#imports
import struct
from array import array
from os.path import join
import numpy as np
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import random
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

#set device to GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device is ", device)
torch.manual_seed(123)
np.random.seed(123)

#model parameters
batch_size = 12 #60000 should be divisible by this number
num_epochs = 450


class MnistDataloader1(object):
    def __init__(self, training_images_filepath, training_labels_filepath,
                 test_images_filepath, test_labels_filepath):
        self.training_images_filepath = training_images_filepath
        self.training_labels_filepath = training_labels_filepath
        self.test_images_filepath = test_images_filepath
        self.test_labels_filepath = test_labels_filepath

    def read_images_labels(self, images_filepath, labels_filepath):
        with open(labels_filepath, 'rb') as file:
            magic, size = struct.unpack(">II", file.read(8))
            if magic != 2049:
                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))
            labels = array("B", file.read())

        with open(images_filepath, 'rb') as file:
            magic, size, rows, cols = struct.unpack(">IIII", file.read(16))
            if magic != 2051:
                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))
            image_data = array("B", file.read())

        images = []
        for i in range(size):
            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols], dtype=np.float32)
            img = img.reshape(28, 28)
            images.append(img)

        return images, labels
    
    def load_data(self):
        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)
        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)
        
        # Convert to PyTorch tensors
        x_train_tensor = torch.tensor(x_train) / 255.0
        y_train_tensor = torch.tensor(y_train, dtype=torch.float) / 10
        x_test_tensor = torch.tensor(x_test) / 255.0
        y_test_tensor = torch.tensor(y_test, dtype=torch.float) / 10
        
        return (x_train_tensor, y_train_tensor), (x_test_tensor, y_test_tensor)
    

#TODO make the first dataloader object do9 this as well by changing load_data to __getitem__ and returning [index] of each one
class MnistDataLoaderTrain(object):
    def __init__(self, x_train_tensor, y_train_tensor):        
        self.x_train_tensor = x_train_tensor
        self.y_train_tensor = y_train_tensor

    def __len__(self):
        return x_train_tensor.shape[0]

    def __getitem__(self, index):
        #print(self.y_train_tensor[index])
        return (self.x_train_tensor[index], self.y_train_tensor[index])

    
# Set file paths based on added MNIST Datasets
input_path = r'C:\Users\Matt\Documents\Pytorch_ML\Generative\GAN\Data\archive'
training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')
training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')
test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')
test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')

# Load MNIST dataset
mnist_dataloader = MnistDataloader1(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)
(x_train_tensor, y_train_tensor), (x_test_tensor, y_test_tensor) = mnist_dataloader.load_data()     #for purposes of displaying images in the beginning

dataLoaderTrain = MnistDataLoaderTrain(x_train_tensor, y_train_tensor)

#TODO: consolidate train and test dataloaders into one? for both this and random numbers?
mnistDataSetTrain = DataLoader(dataLoaderTrain, batch_size = batch_size, shuffle = False)




# Helper function to show a list of images with their relating titles
def show_images(images, title_texts):
    cols = 5
    rows = int(len(images) / cols) + 1
    plt.figure(figsize=(14, 14))
    index = 1
    for x in zip(images, title_texts):
        image = x[0]
        title_text = x[1]
        plt.subplot(rows, cols, index)
        plt.imshow(image.cpu().detach().numpy(), cmap=plt.cm.gray)
        if title_text != '':
            plt.title(title_text, fontsize=15)
        index += 1
    plt.show(block = False)   # Show the image
    plt.pause(3.5)
    plt.close("all")  # Close the figure after showing

# Show some random training and test images
images_2_show = []
titles_2_show = []

for i in range(0, 10):
    r = random.randint(0, 59999)
    images_2_show.append(x_train_tensor[r].numpy())
    titles_2_show.append('training image [' + str(r) + '] = ' + str(y_train_tensor[r].item()))

for i in range(0, 5):
    r = random.randint(0, 9999)
    images_2_show.append(x_test_tensor[r].numpy())
    titles_2_show.append('test image [' + str(r) + '] = ' + str(y_test_tensor[r].item()))

#show_images(images_2_show, titles_2_show)




#_______________________________________________________ model time ________________________________________________________________________________________

img_size = x_train_tensor[0].size(0)
print("Image size is", img_size)
print("Entire tensor size is ",x_train_tensor.size())

class Generator(nn.Module):
    def __init__(self, input_length, batch_size):
        super(Generator, self).__init__()
        
        self.batch_size = batch_size
        self.input_length = input_length
        
        # Linear FC layer to create multiple representations of the same thing
        # Decoding layers (upsampling)
        self.deconv1 = nn.ConvTranspose2d(in_channels = 1, out_channels = 64, kernel_size = 4, stride = 2, padding = 1)
        self.deconv2 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)
        self.deconv3 = nn.ConvTranspose2d(32, 1, kernel_size=4, stride=4, padding=211, output_padding = 2)

        # Batch normalization layers
        self.bn4 = nn.BatchNorm2d(64)
        self.bn5 = nn.BatchNorm2d(32)

    def forward(self, x):
        
        
        x = x.view(batch_size, 1, self.input_length, self.input_length)
        
        #print(f"Intro x shape {x.shape}")

        x = F.relu(self.bn4(self.deconv1(x)))
        
        #print(f"level 2 x shape {x.shape}")
        x = F.relu(self.bn5(self.deconv2(x)))

        #print(f"level 3 x shape {x.shape}")
        # Final output layer with tanh activation
        x = torch.tanh(self.deconv3(x))
        #print(f"level 5 x shape {x.shape}") 
        # Remove the channel dimension to return to the original input shape
        x = x.view(self.batch_size, self.input_length, self.input_length)
        #print(x.shape)

        return x
    
class Discriminator(nn.Module):
    def __init__(self, input_length, batch_size):
        super(Discriminator, self).__init__()
        
        self.batch_size = batch_size
        self.input_length = input_length
        
        # Convolutional layers
        self.conv1 = nn.Conv2d(batch_size, 64, kernel_size=5, stride=2, padding=2)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)
        
        # Fully connected layers
        self.fc1 = nn.Linear(64**2, 256)
        self.fc2 = nn.Linear(256, batch_size)
        
        # Dropout for regularization
        self.dropout = nn.Dropout(0.3)

    def forward(self, x):
        # Reshape the input to match convolutional input size
        x = x.view(-1, self.input_length, self.input_length)

        # Convolutional layers with ReLU activation
        x = F.leaky_relu(self.conv1(x))
        x = F.leaky_relu(self.conv2(x))
        x = F.leaky_relu(self.conv3(x))
        
        # Flatten the output from the convolutional layers
        x = torch.flatten(x)
        
        # Fully connected layers with ReLU and Dropout
        x = F.leaky_relu(self.fc1(x))
        x = self.dropout(x)
        
        # Output layer with sigmoid activation
        x = torch.sigmoid(self.fc2(x))
        
        return x

        
def Train(epochs, verbose, showImages):
    generator = Generator(img_size, batch_size).to(device)
    discriminator = Discriminator(img_size, batch_size).to(device)
    generator_opt = torch.optim.Adam(generator.parameters(), lr=0.001)
    discriminator_opt = torch.optim.Adam(discriminator.parameters(), lr=0.001)
    loss = nn.BCELoss()

    for i in range(epochs):
        
        correct_predictions = 0
        total_predictions = 0
        
        generator_opt.zero_grad()
        noise = torch.from_numpy(np.random.rand(img_size, img_size)).to(device)
        for x_train_tensor, _ in mnistDataSetTrain:
           
            real_images = x_train_tensor.to(device)
            
            #train discriminator on real images
            discriminator_opt.zero_grad()
            label_real = torch.ones(batch_size).to(device)
            output_real = discriminator(real_images)
            loss_real = loss(output_real, label_real)
            loss_real.backward()

            # Train discriminator with fake images
            noise = torch.randn(batch_size, img_size, img_size).cuda()
            fake_images = generator(noise)
            label_fake = torch.zeros(batch_size, 1).cuda()
            output_fake = discriminator(fake_images.detach()).view(-1, 1)
            loss_fake = loss(output_fake, label_fake)
            loss_fake.backward()
            discriminator_opt.step()

            # Train generator
            generator_opt.zero_grad()
            output = discriminator(fake_images).to(device)
            loss_g = loss(output, label_real)
            loss_g.backward()
            generator_opt.step()


                
            if ((i + 1) % 100 == 0) & verbose == True:
                print(f'Epoch [{i+1}/{num_epochs}], Batch [{i+1}/{len(mnistDataSetTrain)}], '
                    f'D_real: {output_real.mean():.4f}, D_fake: {output_fake.mean():.4f}, '
                    f'Loss_D: {loss_real.item() + loss_fake.item():.4f}, Loss_G: {loss_g.item():.4f}')
                # Generate and save sample images at the end of each epoch

              
        if showImages == True:
            title = f"Epoch [{i+1}/{epochs}] generated image"
                #just doing 11 random images for now
            show_images(fake_images[0:10], title)

    if saveModel == True:
        return noise, generator, discriminator, saveModel


saveModel = True

if(saveModel == True):
    noise, generator, discriminator,_ = Train(num_epochs, verbose=True, showImages=saveModel)
else:
    Train(num_epochs, verbose=True, showImages=saveModel)
